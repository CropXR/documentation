{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":"<p>CropXR is a leading Dutch research institute dedicated to developing climate-resilient crops through innovative \"smart breeding\" technologies. Building on the Netherlands' renowned expertise in plant biology, agricultural sciences, and plant breeding, CropXR integrates cutting-edge  experimental research with artificial intelligence and computational modeling. Our interdisciplinary approach enables us to develop advanced  technologies and methodologies that generate new crop varieties specifically engineered to thrive amid climate change challenges while  reducing dependence on environmentally harmful agricultural interventions.</p> <p>For inquiries, please contact us at data@cropxr.org</p>"},{"location":"defining-a-study/","title":"Defining a study","text":"<p>As a researcher you are free to define studies as you need. Here are some tips and constraints to help you.</p> <p>Investigation - larger topic with several standalone subquestions. Size of PhD, or the work of several researchers combined. Typically a PI will have a plan for how the investigations are defined.</p> <p>Study - roughly the size of a paper. A standalone set of relevant data that together answers a research question. Multiple people can work together on a study.</p> <p>If multiple experiments are performed on the same plant and they need to be combined to come to an understanding these experiments should be grouped in a study. It is not possible to directly reference plants/samples in another study. If plants are grown in the same batch, but separated, to perform different analyses and answer different questions they are likely best separated into different studies. Simply copy the growth conditions.</p> <p>While CropXR does not require this, MIAPPE assumes that a study is in a single location. If you wish to stay close to the MIAPPE format, be sure to separate measurements performed at different locations into different studies.</p>"},{"location":"what-data-to-upload/","title":"What data to upload","text":""},{"location":"what-data-to-upload/#wip-what-data-to-upload","title":"[WIP] What data to upload","text":"<p>Think about the purpose</p> <p>Standards will be developed by the consortium during the time of the consortium</p> <p>Reach out to each other (link slack channel)</p>"},{"location":"what-data-to-upload/#raw-data","title":"Raw data","text":"<p>This makes it possible to re-use data from different studies and process it all in the exact same way.</p> <p>Legal requirement.</p> <p>What is raw data? (e.g. not pod5, yes fastq)</p>"},{"location":"what-data-to-upload/#processed-data","title":"Processed data","text":"<p>Output artifacts that considered valuable. These might be used by researchers to understand the study and it's outcomes. The data might also be used directly in a secondary analysis,  especially if the data was produced by one of the CropXR standerdized pipelines or scripts. Do not include intermediates that can be regenerated from the raw data and have no direct value.</p> <p>Typically included: - count tables</p> <p>Typically not included: - graphs used in the paper - BAMs</p>"},{"location":"Resilience-Hub/","title":"Resilience Hub","text":"<p>\ud83d\udea7 This section is currently under construction. Check back soon for updates. \ud83d\udea7</p>"},{"location":"Resilience-Hub/metadata-entry-seek/","title":"Introduction","text":"<p>The ResilienceHub uses FairdomSEEK with ISA settings as the metadata catalogue. This document describes how metadata can be uploaded in the right format. This document contains a detailed step by step guide for first time data entry. A shorter reference guide for additional studies will be included later.</p> <p>There is a format to stick to, but also the format accommodates for many type of studies, so it leaves room to fill out differently. This puts some responsibility on the researcher for how to use this format and to really understand the model. The documents guide you through the choices you need to make, and how you can make them. Do plan time for this, especially the first time.  If you are stuck at any point, things are unclear or you need help, please reach out to the DataXR team at data@cropxr.org</p>"},{"location":"Resilience-Hub/metadata-entry-seek/#process-outline","title":"Process outline","text":"<p>We suggest you do phase 0 a few days before you plan to do your metadata entry and that you do step 1 and 2 in one session. </p>"},{"location":"Resilience-Hub/metadata-entry-seek/#phase-0-preparations","title":"Phase 0: preparations","text":"<p>Get an overview over the process and prepare data entry. Importantly, read this document all the way through (except the detailed step-wise instructions of phase 2, 3 and 4). Try to understand the process, the metadata model, and the concepts. You will define the study by choosing what experiments to include and make sure you are registered upfront. An admin from DataXR might need to approve requests, so make sure to do this a few days before your planned data entry. You gather files that contain metadata regarding your study.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/#phase-1-define-study-assays-and-sample-templates","title":"Phase 1: define study, assays and sample templates","text":"<p>In the web interface, create (an investigation and) study. Choose what fields to include in your study to properly capture the metadata. Define assays for the experiments performed in the study. </p>"},{"location":"Resilience-Hub/metadata-entry-seek/#phase-2-critical-metadata-entry","title":"Phase 2: critical metadata entry","text":"<p>Decide how to the metadata should be entered, to capture all information that is needed, by grouping conditions and samples. In the web interface, fill in all the fields that are essential to understand the study, focusing on key aspects, such as species and assay type. In this phase you also link the data to the performed experiments, so others can find and understand your data. </p>"},{"location":"Resilience-Hub/metadata-entry-seek/#phase-3-improving-metadata","title":"Phase 3: improving metadata","text":"<p>When the fields have been defined, at any point in time you can save the metadata and edit it later. Add the additional metadata that was collected, and improves the re-usability of your data. You can also manage who can see your metadata at any time.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/high-level-example/","title":"High level example","text":""},{"location":"Resilience-Hub/metadata-entry-seek/high-level-example/#experimental-design","title":"Experimental design","text":"<p>2 varieties (col-0, ler) and 2 watering regimes (well watered, drought) -&gt; 4 experimental groups. Measurements: - RNA-seq of root and and leaf samples - Canopy coverage per experimental group - Some general measurements from the greenhouse.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/high-level-example/#study-general","title":"Study general","text":"<p>Choose combined sequencing and phenotyping study. Add SOP with experimental design map for MIAPPE.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/high-level-example/#study-source","title":"Study source","text":"<p>Create one source per experimental group. Specify the variety and watering regime. Add additional information that is relevant.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/high-level-example/#study-samples","title":"Study samples","text":"<p>Create samples of type \u2018sample\u2019 for each root sample taken. The input is the source of the experimental group that the plant was grown in. Specify the plant structure/anatomical entity as root. </p> <p>Create samples for the leave samples in the same way.</p> <p>Create samples of type \u2018observation_unit\u2019 for each experimental group. The level is \u2018plot\u2019. The input is the source of that experimental group.</p> <p>Create a sample of type \u2018observation_unit\u2019 that combine all sources. The level is \u2018greenhouse\u2019. </p>"},{"location":"Resilience-Hub/metadata-entry-seek/high-level-example/#assays","title":"Assays","text":"<p>Create one phenotyping assay stream for canopy coverage and fill in all the information about the trait and the method. Create an assay with as output a data file. Create a row for each separate measurement/experimental group, with as input the observation unit plots.  Describe the output data file of the measurement and link to the data. </p> <p>Create one sequencing assay stream. Describe the library construction and sequencing. Create an assay with as output a data file. Create a row for each measurement, with as input a sample. Describe the output data file of the measurement and link to the data. </p> <p>Create one phenotyping assay stream for the greenhouse sensors. Create an assay for the measurements of the output material with the template observation. Define one row per environment variable measured by the greenhouse sensors, describing the variable, the sensor and the scale. This can be one row for temperature and one for humidity. The input is the study observation unit greenhouse. Create a next assay in the stream for the data files, one row for each file, with as input the assay row defined in the previous assay. Describe the and link to the data. </p>"},{"location":"Resilience-Hub/metadata-entry-seek/metadata-entry-seek/","title":"Detailed instructions","text":"<p>Important!! This guide is still under development.  Any metadata uploaded in the catalogue is not yet backed up.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/metadata-entry-seek/#phase-0","title":"Phase 0","text":"<ol> <li> <p>Understand the basic structure of the metadata model. </p> </li> <li> <p>Decide on the what experiments to group into (the investigation and) the study.</p> </li> <li> <p>Choose the study type (sequencing, phenotyping or combined). Inform DataXR well up front when your study does not fit these types.</p> </li> <li> <p>Make sure that you have registered your study in this form. After the admin has checked the registration, you will receive a study id you need when entering the metadata, as well as storage for your experimental data. </p> </li> <li> <p>Create an account for the catalogue and log in.     [Write about normal or KeyCloak?]</p> <p>Request to be added to a project. This is done by a project admin. </p> </li> <li> <p>Gather the files with the metadata that you already collected. This includes e-lab journal entries, files that outline experimental conditions per plant, files that link output files to the experiment, etc.</p> </li> </ol>"},{"location":"Resilience-Hub/metadata-entry-seek/metadata-entry-seek/#phase-1","title":"Phase 1","text":"<ol> <li> <p>Log in to the FairdomSEEK webpage.</p> </li> <li> <p>Find or create an investigation.</p> <ol> <li>To find an investigation, click on \u201c\ud83d\udd0eBrowse\u201d (click the menu first when using a narrow window) in the top left corner and select \u201cInvestigations\u201d.</li> <li>If your investigation is not yet registered, click on \u201c\u2795Create\u201d and select \u201cInvestigations\u201d. Add a Title and select a Project and click on \u201cCreate\u201d.</li> </ol> </li> <li> <p>From within the investigation, create a new study by clicking \u201c\u2795Design Study\u201d at the top. </p> <ol> <li>Create a tile using the naming convention.</li> <li> <p>Choose the extended metadata type that is relevant for your study. </p> <p>Of the extended metadata, only fill the mandatory fields for now (to be able to save). The other fields can still be entered later. Quickly skim the fields so you are aware of what is collected on study level.</p> </li> <li> <p>For now, skip the fields \u201cStudy position\u201d, \u201cSharing\u201d, \u201cCreators\u201d, \u201cPublications\u201d, and \u201cDiscussion Channels\u201d. The fields \u201cSharing\u201d, \u201cCreators\u201d, \u201cPublications\u201d can be reviewed and modified later.</p> </li> <li> <p>At \u201cDefine Sample type for Source\u201d, select an \u201cExisting template\u201d. Choose the default template \u201cCropXR source\u201d and click \u201cApply\u201d. Now review the predefined parameters that are collected for the study source. These are the fields that will be used to describe your experimental setup and conditions. If there are any missing, you can add them at the bottom by selecting \u201c\u2795Add new attribute\u201d. Make sure that the column \u201cISA Tag\u201d is set to \u201csource_characteristic\u201d. Additional fields can also be added later.</p> <p>In MIAPPE there are many suggestions for environmental parameters and experimental factors to collect. Please reference these lists, to get a predictable field name.</p> <p>Please do not remove any fields; this will make your study harder to find. All fields not relevant to your study can be left empty.</p> <p></p> </li> <li> <p>Skip \u201cSOPs\u201d for now, these will be added later.</p> </li> <li> <p>At \u201cDefine Sample type for Sample\u201d at select an \u201cExisting template\u201d you need to \u201cChoose a template\u201d in the drop down selection. Now select, depending on the units of measurement in your study: \u201cCropXR sample\u201d when there are samples only, \u201cCropXR sample or observation unit\u201d if there are both samples in your study as well as measurements on a different level, and \u201cCropXR observation unit\u201d when there are no samples. Choose the latest version of the template you need, and click \u201cApply\u201d. Here you can also check the fields and add additional fields when needed, as describe for the source, while it is likely not needed.</p> </li> <li> <p>Click on \u201c\ud83d\udfe6Create\u201d</p> </li> </ol> </li> <li> <p>Make a plan for how to define the Assay Streams and Assays. (read here)</p> </li> <li> <p>Click on \u201c\u2795Design Assay Stream\u201d at the top of the study, enter a title (following the naming convention).</p> </li> </ol> <p>If needed, select the \u201cExtended metadata\u201d for the assay stream. Skip all other fields for now and click on \u201c\ud83d\udfe6Create\u201d.</p> <ol> <li>From the created Assay Stream, create an assay by clicking \u201c\u2795Design Assay\u201d<ol> <li>Enter a title (following the naming convention)</li> <li>For now skip the fields \u201cSharing\u201d, \u201cCreators\u201d, \u201cSOPs\u201d, \u201cPublications\u201d, \u201cDocuments\u201d and \u201cChannel discussions\u201d. </li> <li>At \u201cDefine Sample type for Assay\u201d start at the \u201cExisting Templates\u201d. Depending on the type of assay you are making (based on the plan made in step 4), change the \u201cISA Level\u201d drop down to \u201cassay - data file\u201d or leave it as is. Choose the latest version of the relevant template in the drop down menu and \u201cApply\u201d. </li> <li>The sample type can be expanded with additional columns that should be included as metadata. This is relevant for assays where most parameters are kept constant, but some are varied between measurements/samples. If the fields is related to the assay performed, the column \u201cISA Tag\u201d should be set to \u201cparameter_value\u201d, if it is about the output data file set it to \u201cdata_file_characteristic\u201d. </li> </ol> </li> <li>If needed (not included already in the assay), create the next assay of the type data file for the raw data. </li> <li>If needed, create the next assay of the type data file for the derived data.</li> </ol> <p>Now you have the outline of your metadata structure. The actual metadata can be uploaded.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/metadata-entry-seek/#phase-2","title":"Phase 2","text":"<p>Not all steps need to happen in this exact order, but some steps are dependent on each other: study sources need to be created before study samples and study samples before assay row entries. Data files need to be registered before they can be referenced.</p> <ol> <li> <p>Register your data files</p> <ol> <li>At the top menu under \u201c\u2795Create\u201d choose \u201cData file\u201d </li> <li>Choose how you want to register your data. Find the URL at the data location (Research Drive).</li> <li>Under the tab \u201cRemote URL\u201d past the URL of the data location and \u201c\ud83d\udfe6Register\u201d. Do not mind a warning about the URL in a yellow box. If there is an error and the URL cannot be registered please check if the URL is correct. </li> <li>Fill in a \u201cTitle\u201d, a \u201cDescription\u201d, select a \u201cProject\u201d, click \u201c\ud83d\udfe6Next, and \u201c\ud83d\udfe6Next\u201d </li> <li>Select a license. The license can be adapted later if needed. At no license the consortium agreement applies to all people users that this data is shared with. </li> <li>Adapt the sharing of the data, either on group level or per group. At a later stage, the permissions set here automatically apply to where the data is stored. For now, that is still handled separately in the research drive. </li> <li>Skip \u201cAssociated Assays\u201d and \u201cOther associated items\u201dby clicking \u201c\ud83d\udfe6Next, and \u201c\ud83d\udfe6Create\u201d</li> </ol> </li> <li> <p>Add SOPs (Standard operating procedure) (can also be done later).     Each step can reference a protocol that was used: creation of samples and the grouping of observation units at the study level, the assaying protocols at assay level and the data transformation steps.</p> <ol> <li>At the top menu under \u201c\u2795Create\u201d choose \u201cSOP\u201d</li> <li>Click \u201cBrowse\u201d to upload a local file.</li> <li>Add a \u201cTitle\u201d. This needs to be specific enough to find the SOP back between other SOPs from different studies.</li> <li>Add a \u201cDescription\u201d, select a \u201cProject\u201d and a \u201cLicense\u201d. Skip \u201cDiscussion Channels\u201d, adapt \u201cSharing\u201d, skip \u201cCreators\u201d, \u201cTags\u201d and \u201cAttributions\u201d</li> <li>If the SOP is related to an assay, it can be linked under \u201cExperimental assays and Modelling analyses\u201d. This can also be done at the assay. </li> <li>If a data processing step is described by a registered workflow/processing pipeline, it can be linked under \u201cWorkflows\u201d. </li> <li>Click \u201c\ud83d\udfe6Register\u201d</li> </ol> </li> <li> <p>Edit the study by going to \u201c\u2699\ufe0fActions\u201d in the top corner and then \u201c\ud83d\udcddEdit ISA Study\u201d</p> <ol> <li>Fill in the description</li> <li>Fill in extended metadata. Focus on the fields most relevant to understand the study. Skip the fields that do not apply. The fields can always be revised later. </li> <li>Under \u201cSOPs\u201d select the SOP(s) that describe the sampling and the experimental design map. </li> <li>Click \u201c\ud83d\udfe6Update\u201d to apply the changes.</li> </ol> </li> <li> <p>Define study source samples</p> <ol> <li>Choose how to group/define the sources.</li> <li>Go to the \u201cSources table\u201d, by clicking the tab \u201cStudy design\u201d (or from the \u201cSingle page\u201d view find the \u201cSources table\u201d in the left menu). Here you find a table with the columns that you have defined. </li> <li>Download the template by clicking the button \u201cBatch download to Excel\u201d. </li> <li>In the excel, under the Samples tab fill in the data in the fields. <ol> <li>Ignore the first two columns.</li> <li>The Source Name is the name that will be displayed.</li> <li>Start with the most relevant fields to understand the study and the sources used. The data can be improved on at a later point. Fill in at least the species and the experimental group. </li> </ol> </li> <li> <p>Save the file. Upload it by under \u201cUpload excel spreadsheet\u201d select \u201cBrowse\u201d and click \u201c\ud83d\udfe6Upload\u201d. Now there might be an error message. Please read it carefully and adjust the data accordingly.</p> <p>Be aware, if you upload the same excel multiple times, a new sample will be created with the same name. To check how to update existing samples, check the phase 3 instructions.</p> </li> </ol> </li> <li> <p>Define study samples</p> <ol> <li>Choose what type are needed.</li> <li>Go to \u201cSamples table\u201d under \u201cStudy design\u201d(or from the \u201cSingle page\u201d view find the \u201cSamples table\u201d in the left menu).</li> <li>Download the template by clicking the button \u201cBatch download to Excel\u201d.</li> <li>In the excel, under the Samples tab fill in the data in the fields. <ol> <li>Ignore the first two columns.</li> <li>Use the Input column to link to a source defined in the previous step.</li> <li>The subject_id is the name that will be displayed.</li> <li>There is a mandatory column called protocol. The text should refer to a registered SOP.</li> <li>Start with the most relevant fields. The data can be improved on at a later point. </li> </ol> </li> <li>Save the file. Upload it by under \u201cUpload excel spreadsheet\u201d select \u201cBrowse\u201d and click \u201c\ud83d\udfe6Upload\u201d. Now there might be an error message. Please read it carefully and adjust the data accordingly.</li> </ol> </li> <li> <p>Fill in the assay stream extended metadata by going to  \u201c\u2699\ufe0fActions\u201d in the top corner and then \u201c\ud83d\udcddEdit Assay Stream\u201d. Focus on the fields that are most important and \u201c\ud83d\udfe6Update\u201d to save.</p> </li> <li> <p>For each assay defined in phase 1, enter the row data, the same way as the study source and sample: download the template, fill in the data, save and upload the template.</p> <ol> <li>For the first assay of an assay stream the input should be a study sample (so this is a sample of observation unit). For additional assays the input is an output of the previous assay. </li> <li>To link a registered data file as file location, use the required format.</li> <li>For the file name, use the relative path of the exact file inside the registered file location. </li> </ol> </li> </ol>"},{"location":"Resilience-Hub/metadata-entry-seek/metadata-entry-seek/#phase-3","title":"Phase 3","text":"<ol> <li>Update the sharing permissions that each of the created elements have. Think about who should see your study. If you are collaborating with others you can give them edit permission.      You can edit them by navigating to the Study/Assay/DataFile/SOP, clicking \u201c\u2699\ufe0fActions\u201d in the top corner and then \u201c\ud83d\udd27Manage ..\u201d After making the changes make sure to \u201c\ud83d\udfe6Update\u201d</li> </ol> <p>Note that in the future the permission you set in SEEK on the data file will be automatically set where the data is stored, but for now the permission is still set separately within the Research Drive.</p> <ol> <li> <p>Update the study and assay extended metadata to make the metadata more complete (under \u201c \u201c\u2699\ufe0fActions\u201d in the top corner and then \u201c\ud83d\udcddEdit ..\u201d)</p> </li> <li> <p>Updating existing samples [todo: expand]</p> <ol> <li>make sure it\u2019s selected before downloaded, so there is no new sample with the same name</li> <li>You can upload multiple in multiple steps, but be aware that if you re-upload samples with the same name, a new sample will be created. Only upload new samples.</li> </ol> </li> <li> <p>Adding additional columns  [todo: expand] (under \u201c \u201c\u2699\ufe0fActions\u201d in the top corner and then \u201c\ud83d\udcddEdit ..\u201d)</p> </li> </ol>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/","title":"Reference","text":""},{"location":"Resilience-Hub/metadata-entry-seek/reference/#isa-fairdomseek-structure","title":"ISA FairdomSEEK structure","text":"<p>The ISA format is widely used to represent research data. It is often used to represent MIAPPE data. FairdomSEEK uses the ISA structure, somewhat adapted.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#assay-and-sample-definition","title":"Assay and sample definition","text":"<p>In the ISA format, you can perform assays on samples. It assumes that in an experiment, there are several steps called a process. Each process has an input and an output and a protocol, that describes how the output was created from the input. The input can be either a material or data, and the output as well. These processes can be chained together. Here is an example:</p> <pre><code>step 1 sample collection (input plant material-&gt; output sample)\nstep 2 DNA extraction and library prep (input sample -&gt; output sample) \nstep 3 sequencing (input sample -&gt; output data)\nstep 4 analysis (input data -&gt; output data)\n</code></pre> <p>In ISA these processes are organized the following way: the study contains 1 process with a material input (study source) to a material output (study sample). The other processes, however many needed, are grouped under the assay. The assay can consist of several steps/processes and starts with the study sample.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#isa-in-fairdomseek","title":"ISA in FairdomSEEK","text":"<p>In FairdomSEEK, the processes that are grouped under the assay, are all called an assay even if the input and output are both a material object, or both data files. This does not fit with the classical meaning of the word \u2018assay\u2019, but it implements the same functionality as ISA. The assays can be connected into an assay stream. </p> <p>Each row, that can describe a sample, but also an assay performed on a sample, or a derivation of a data file, is called always a \u2018sample\u2019 in FairdomSEEK.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#miappe-and-ena-in-fairdomseek","title":"MIAPPE and ENA in FairdomSEEK","text":"<p>[todo: write]</p> <p></p> <p>intro to data model</p>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#observation-units-and-samples","title":"Observation units and samples","text":"<p>Level where a measurement is done.</p> <p>Whole greenhouse, per plot, plant, sample.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#naming-conventions","title":"Naming conventions","text":"<p>[todo: finish]</p> <p>Study:</p> <pre><code>&lt;received study id&gt; - &lt;study name&gt;\nexample \u201cCXRS4 - Drought response of arabidopsis after hormal treatment with PAMP\u201d\n</code></pre> <p>Assay stream:</p> <pre><code>&lt;received study id&gt; - &lt;descriptive assay name&gt;\n</code></pre> <p>Assay: </p>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#references-inside-sample-templates","title":"References inside sample templates","text":""},{"location":"Resilience-Hub/metadata-entry-seek/reference/#sample-inputs","title":"Sample inputs","text":"<p>Unfortunately in FairdomSEEK the names of the samples are not used as identifiers. For this reason the column where you link to samples from the previous section (marked Input) needs to be formatted like this: </p> <pre><code>[{\"id\"=&gt;343, \"type\"=&gt;\"Sample\", \"title\"=&gt;\"yeast_wgs_02\"}]\n</code></pre> <p>You can read more here.</p> <p>When you are entering this data, it might be convenient to make a column with the ids that the catalogue has generated, and one with the sample titles, and use excel formulas to create the required format, and copy the values into the upload sheet.</p> <pre><code>=\"[{\"\"id\"\"=&gt;\"&amp;A1&amp;\", \"\"type\"\"=&gt;\"\"Sample\"\", \"\"title\"\"=&gt;\"\"\"&amp;B1&amp;\"\"\"}]\"\n</code></pre>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#data-files","title":"Data files","text":"<p>To link a registered data file use the following format. </p> <pre><code>{\"id\"=&gt;1, \"type\"=&gt;\"DataFile\", \"title\"=&gt;\"File from data access layer\"}\n</code></pre> <p>Find the data file ID, by going to the data file in the interface, and checking the number at the end of the URL https://catalogue.cropresilience.org/data_files/1 </p>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#defining-assays","title":"Defining assays","text":"<p>There is some flexibility in how to define assays. In FairdomSEEK, an assay (called assay stream) can be split into steps (called assays) that output material or a data file.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#default-strategy","title":"Default strategy","text":"<ol> <li>Create one assay stream of each type of assay performed.</li> <li>At the assay stream, choose the extended metadata type that fits the type of assay. </li> <li>Fill in all the information that is the same for each measurement in this extended metadata fields.</li> <li>Create inside this assay stream a single assay of the type data file. </li> <li>Add fields for the parameters that are different per measurement.</li> <li>Is the rows/samples of the assay to link the output files of the assay to the measured unit/plant/sample.</li> </ol>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#at-significant-data-processing","title":"At significant data processing","text":"<p>Create a next assay in the same assay stream. The protocol contains the performed data processing step. The output files can be explicitly linked to the input files.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#top-level-sensors","title":"Top level sensors","text":"<p>Top level environmental measurements, with no distinction between rows/samples, can be grouped together in a single assay stream. This allows for linking the data files with the specs of the measurement/instrument, without a large part of the interface being taken up by sensor measurements, that are not relevant for the understanding the study. </p> <ol> <li>Create assay stream for these grouped measurements. Do not choose any extended metadata. </li> <li>Create an assay of the type observation with a material output. In this assay each row describes a type of measurement done. </li> <li>Create a next assay of the type data file. Each row links the output file to the described measurement.</li> </ol>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#multiple-files-per-experiment","title":"Multiple files per experiment","text":"<p>[rewrite]</p> <p>If there are still different experimental conditions or if there are multiple data files per experiment: split into assay and data file separately. Add the different parameter on the assay, and link the files in the second data file assay</p>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#limitation","title":"Limitation","text":"<p>It is not possible to link derived data files to input files from multiple assay streams. There is no clear place to list key output artifacts, that summarize the conclusions of the study.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#registering-data-files","title":"Registering data files","text":"<p>You can register a URL that contains a file or a folder.</p> <p>The advise is to register a folder that is both </p> <pre><code> easy to navigate inside, \ncontaining for example only one data type and no different types of sub-folders\n\nthe same permissions apply to the whole folder\n</code></pre> <p>An example would be: the all raw reads of a sequencing experiment.</p> <p>The metadata is used to link certain experiments and samples to the files. Here you can indicate what file in the registered folder contains what data.</p> <p>At a later stage, the permission set in SEEK will be applied to the data download. If you only register the whole study as a single data file, it is not possible to apply granular permissions on who can download your data.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#grouping-samples","title":"Grouping samples","text":"<p>[consider moving to top section explaining the model]</p>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#study-source","title":"Study source","text":"<p>Choose the granularity that is needed for your metadata. The sources are used to specify the biological material, as well as the growth conditions. At least each experimental block needs to be defined as a separate source. If the metadata and a sample needs to be traced back to a certain plant, you might define a source per plant.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/reference/#study-samples","title":"Study samples","text":"<p>The study samples section is used both for samples, as well as for defining observation units.  Observation units are any level, where a measurement/observation is done. How to define this will depend on the specific design of a study, and typically be the unit for which each experiment generates a file. Think about the assays and the data files when defining the observation units.</p>"},{"location":"Resilience-Hub/metadata-entry-seek/short-guide/","title":"Short guide","text":"<p>Detailed instructions are found here</p> <p>Prepare</p> <ol> <li>register the study in the form and get storage </li> <li>gather relevant documents, such as lab notes and experimental design overviews</li> </ol> <p>Start with the metadata entry in FairdomSEEK</p> <ol> <li>create a study<ol> <li>choose an extended metadata type</li> <li>set the sharing of the study</li> <li>choose a template for the study source. Add additional fields if needed.</li> <li>choose a template for the study sample (sample only, observation unit, or combined)</li> </ol> </li> <li>for each assay type create an assay stream<ol> <li>select the right extended metadata</li> <li>set the sharing</li> </ol> </li> <li>within the assay stream create one or more assays <ol> <li>choose a sample template that fits the type of assay (choose between material and data file + choose the full or condensed + choose sequencing or observation)</li> <li>add additional fields if needed</li> <li>add additional assays for data files that were generate from the first assay output</li> </ol> </li> </ol> <p>Now the study has been defined, continue with the minimally needed metadata.</p> <ol> <li>Register Data files by linking the URL to the file or folder. Manage the permissions on the file. </li> <li>Register protocols under SOPs and manage the permissions. </li> <li>Edit the study to fill the extend metadata and link SOPs.</li> <li>Define sources, based on your specific study and the level of granularity needed.</li> </ol> <p>Enter the data by downloading the template, filling the data and uploading. 10. Define samples/observation units, based on your specific study and the level of granularity needed.</p> <pre><code>Enter the data by downloading the template, filling the data, referencing the study sources by name and id, and uploading the template in the interface.\n</code></pre> <ol> <li>Edit assay metadata </li> <li>Enter assay row data + link data files</li> </ol> <p>Now that the minimal metadata is added, continue improving the metadata.</p> <ol> <li>adapt permissions </li> <li>update with additional data</li> </ol>"},{"location":"current-system/","title":"Introduction","text":""},{"location":"current-system/#metadata","title":"Metadata","text":"<p>All the research produced in the CropXR consortium will be well annotated with metadata following the CropXR standards. </p> <p>The metadata annotation will have multiple uses:   - Findability of your study, by other researchers in the consortium   - Reusability of your data by other users in the consortium   - Improvement of your own data annotation</p> <p>The responsibility to annotate the data lies with the researcher, with the help and tools provided by DataXR.</p>"},{"location":"current-system/#model-flexibility","title":"Model flexibility","text":"<p>A standardized metadata format ensures that the metadata has a predictable structure.  There are however many different types of studies in the consortium, with different metadata that is important.  To fit all different studies in the same format there is a certain flexibility in the model. This puts some responsibility on the researcher for how to use this format and to really understand the model.  These documents should provide the information needed to make those choices.  For the first time entering metadata, plan sufficient time to understand the model. If you are stuck at any point, things are unclear, or you need help, please reach out to the DataXR team at data@cropxr.org</p>"},{"location":"current-system/#catalogue","title":"Catalogue","text":"<p>The metadata is currently collected in Excel templates.  The metadata that is collected in these templates, will be imported into a catalogue.  In this catalogue people of the consortium can find studies, view and download the metadata en view the associated data.  In the catalogue, the data producing researchers will also be able to manage who can view their study.  It will be made available to you as soon as possible.</p> <p>[insert screenshot of catalogue with example studies]</p>"},{"location":"current-system/#data","title":"Data","text":"<p>The data storage is currently the Research Drive. In the future there might be other data storages added. The metadata will include a link to where the data is stored.</p>"},{"location":"current-system/introduction-metadata-model/","title":"Introduction metadata model","text":"<p>ENA MIAPPE combined references etc Pictures too</p> <p>Source: ENA 35 &amp; 37 + additional that turned out quite relevant MIAPPE: the standards for phenotyping</p> <p>There is a lot of overlap: what was grown how</p> <p>From general to measurements to data</p>"},{"location":"current-system/stepwise-guide/","title":"Stepwise guide","text":""},{"location":"current-system/stepwise-guide/#preparations","title":"Preparations","text":"<ol> <li>Understand the basic structure of the metadata model.</li> <li>Decide on the what experiments to group into the study.</li> <li>Choose the study type (sequencing, phenotyping or combined). Inform DataXR well up front when your study does not fit these types.</li> <li>Make sure that you have registered your study in this form. After the admin has checked the registration, you will receive a study id you need when entering the metadata, as well as storage for your experimental data.</li> <li>Gather the files with the metadata that you already collected. This includes e-lab journal entries, files that outline experimental conditions per plant, files that link output files to the experiment, etc.</li> </ol>"},{"location":"current-system/stepwise-guide/#data-upload","title":"Data Upload","text":"<p>Pre-requisites:  - access to the Research Drive - Choose a method of data upload, depending on your data size, and set up the required tools.</p> <ol> <li>Make a plan of what data should be uploaded and how it should be organised in folders.</li> <li>Upload the data inside your designated study folder.</li> </ol>"},{"location":"current-system/stepwise-guide/#minimal-metadata-entry","title":"Minimal metadata entry","text":"<p>Decide how to the metadata should be entered, to capture all information that is needed, by grouping conditions and samples. In the web interface, fill in all the fields that are essential to understand the study, focusing on key aspects, such as species and assay type. In this phase you also link the data to the performed experiments, so others can find and understand your data. </p>"},{"location":"current-system/stepwise-guide/#improving-metadata","title":"Improving metadata","text":"<p>At any point in time you can save the metadata and edit it later. Add the additional metadata that was collected, and improves the re-usability of your data.</p>"},{"location":"current-system/stepwise-guide/#other-things","title":"Other things","text":""},{"location":"current-system/stepwise-guide/#adding-columns","title":"Adding columns","text":"<p>hmmm as little as possible</p>"},{"location":"current-system/stepwise-guide/#combined-study","title":"Combined study","text":""},{"location":"policies/data-sensitivity-levels/","title":"Data sensitivity levels","text":"<p>All data sharing is conducted through the DAC. Approval for sharing depends on the sensitivity level of the data. The DAC oversees five levels of data access:</p> Access Level Description DAC Approval needed for CropXR members? DAC Approval needed for non-CropXR members? Notes Public Data accessible to everyone No No No restrictions or monitoring required Internal Data for internal CropXR use Yes Yes Approval needed to ensure data aligns with organizational use policies Restricted Specific individuals within CropXR, listed in data catalog Yes* Yes* Access logged and monitored. Role-based access rights required Confidential Specific individuals, not listed in catalog Yes* Yes* Limited to select individuals with specific security clearances"},{"location":"research-drive/","title":"Research Drive","text":""},{"location":"research-drive/#what-is-research-drive","title":"What is Research Drive?","text":"<p>Research Drive is SURF's secure cloud storage and collaboration platform designed specifically for the Dutch research community. For the CropXR project, Research Drive serves as our Phase II data sharing infrastructure, providing:</p> <ul> <li>Secure Data Storage: Enterprise-grade security for sensitive research data</li> <li>Collaborative Workspace: Shared environment for interdisciplinary collaboration</li> <li>Version Control: File versioning to track changes and maintain data integrity</li> <li>Large Capacity: Suitable for handling large genomic datasets and high-resolution imaging files</li> </ul>"},{"location":"research-drive/#key-features-for-cropxr-researchers","title":"Key Features for CropXR Researchers","text":"<ul> <li>Accessibility: Access your files from anywhere via web browser or desktop/mobile applications</li> <li>Synchronization: Automatically sync files across multiple devices</li> <li>Sharing Controls: Granular permissions for precise access management</li> <li>Integration: Works with common research tools and analysis platforms</li> <li>Compliance: Meets Dutch and European data protection regulations (GDPR compliant)</li> </ul>"},{"location":"research-drive/#technical-specifications","title":"Technical Specifications","text":"<ul> <li>Storage Allocation: Each project receives dedicated storage based on requirements</li> <li>File Size Limits: Individual files up to 5TB can be uploaded</li> <li>Security: End-to-end encryption for data transfer and storage</li> <li>Backup: Automated backup systems with redundancy</li> <li>Support: Technical support provided by both SURF and the CropXR data team</li> </ul> <p>\u26a0\ufe0f Note: Research Drive is intended for active research data. For long-term archival purposes, completed projects should transition to the CropXR Data Repository [ResilienceHub].</p>"},{"location":"research-drive/#accessing-the-platform","title":"Accessing the Platform","text":"<p>Our Research Drive instance is hosted at https://cropxr.data.surfsara.nl/</p>"},{"location":"research-drive/#links","title":"Links","text":"<ul> <li>Research Drive Wiki</li> <li>Research Drive Tutorials</li> <li>Research Drive Best Practices</li> </ul>"},{"location":"research-drive/How-to-get-access/","title":"How to get access","text":"<p>Getting started with CropXR's data resources involves a simple registration process:</p>"},{"location":"research-drive/How-to-get-access/#step-1-project-initiation","title":"Step 1: Project Initiation","text":"<p>When you're ready to conduct a study using CropXR resources, your first step is to contact our data team.</p> <p>\ud83d\udce7 Contact: data@cropxr.org</p>"},{"location":"research-drive/How-to-get-access/#step-2-registration","title":"Step 2: Registration","text":"<p>After your initial contact, you'll receive a link to our project registration form.</p>"},{"location":"research-drive/How-to-get-access/#step-3-form-completion","title":"Step 3: Form Completion","text":"<p>Complete all required fields in the registration form with details about your research project, required resources, and team members.</p>"},{"location":"research-drive/How-to-get-access/#step-4-storage-allocation","title":"Step 4: Storage Allocation","text":"<p>Upon approval:</p> <ul> <li>You'll receive confirmation via email</li> <li>A dedicated storage folder will be created for your project on Research Drive</li> <li>Access invites will be sent to all approved team members</li> </ul> <p>\ud83d\udca1 Tip: Include all team members who need access in your initial registration to streamline the onboarding process.</p>"},{"location":"research-drive/Uploading-data/","title":"Uploading data","text":"<p>Choose your upload method based on file size and quantity and experience level. Here are the recommended methods for uploading data to Research Drive:</p>"},{"location":"research-drive/Uploading-data/#1-browser-upload","title":"1. Browser Upload","text":"<ul> <li>Best for: Files up to several GB</li> <li>Method: Direct upload through Research Drive interface</li> <li>Read more</li> </ul>"},{"location":"research-drive/Uploading-data/#2-owncloudnextcloud-clients","title":"2. OwnCloud/NextCloud Clients","text":"<p>\u26a0\ufe0f WARNING: This is not recommended until the transition to NextCloud is complete.</p> <ul> <li>Best for: Multiple files or large datasets</li> <li>Features: Automatic handling of large files</li> <li>Supports upload resumption</li> <li>Synchronizes files across devices</li> </ul>"},{"location":"research-drive/Uploading-data/#3-command-line-tools-curlrclone","title":"3. Command Line Tools (curl/rclone)","text":"<ul> <li>Best for: Very large datasets (10-30 GB)</li> <li>Requires: Command line experience</li> <li>Provides maximum upload size capacity</li> <li>Remote access to Research Drive data</li> <li>Read more</li> </ul>"},{"location":"research-drive/sharing-data/","title":"Sharing data","text":"<p>To share folders or files with other users, you can use the \"Share\" option in the Research Drive. This allows you to grant access to specific users or groups, enabling them to view or edit the shared content.</p> <ol> <li>Select the Folder/File: Navigate to the folder or file you want to share and select it, click on the three dots.</li> </ol> <p></p> <ol> <li>Click on \"Details\": In the dropdown menu, click on the \"Details\" option.</li> </ol> <p></p> <ol> <li>Click on \"Sharing\": In the dropdown menu, click on the \"Sharing\" option and add name or email address of the user you want to share with.</li> </ol> <p></p> <ol> <li>Set Permissions: In the sharing settings, you can add users or groups by entering their email addresses. You can also set their permissions (view or edit) and add a message if needed.</li> </ol> <p></p>"},{"location":"research-drive/sharing-data/#sharing-guidelines","title":"Sharing Guidelines","text":"<ol> <li>Sharing Rules:<ul> <li>Only share folders with the workpackage prefix (e.g. 'WPXYZ-')</li> <li>Never share non-prefixed folders (e.g., 'studies', 'assays', 'raw')</li> <li>Always share from the nearest parent folder with 'WPXYZ-' prefix</li> <li>This ensures unique folder names and prevents conflicts</li> <li>Once you uploaded a dataset, remove the write/change/delete permissions for everyone, to keep the data safe</li> </ul> </li> <li>Examples:<ul> <li>\u2705 CORRECT: Share 'WPXYZ-seq1'</li> <li>\u274c INCORRECT: Share 'assays' or 'raw' folders directly</li> </ul> </li> </ol>"},{"location":"research-drive/connecting-to-research-drive/Via-NextCloud/","title":"Via NextCloud","text":"<p>\ud83d\udea7 This section is currently under construction. Check back soon for updates. \ud83d\udea7</p>"},{"location":"research-drive/connecting-to-research-drive/Via-Rclone/","title":"Via Rclone","text":"<p>Rclone is a powerful, open-source command-line program designed for managing files across cloud storage platforms. Often described as the \"Swiss Army knife\" of cloud storage management, Rclone allows users to sync, copy, and transfer files between various cloud storage providers including Google Drive, Dropbox, Amazon S3, Microsoft OneDrive, and many others. Since its creation in 2012 by Nick Craig-Wood, Rclone has become an essential tool for system administrators, developers, and tech-savvy individuals who need to efficiently handle data across multiple cloud environments. With its robust encryption capabilities, extensive configuration options, and ability to handle files of virtually any size, Rclone provides a versatile solution for both personal and enterprise cloud storage management needs. </p> <p>Reference instructions for mounting on Windows by SURF can be found here These steps overlap with the instructions below.</p>"},{"location":"research-drive/connecting-to-research-drive/Via-Rclone/#requirements","title":"Requirements","text":"<p>Version Requirement</p> <p>Rclone version 1.63.1 or newer is required for Nextcloud compatibility. Earlier versions will fail with a chunked upload error.</p>"},{"location":"research-drive/connecting-to-research-drive/Via-Rclone/#installation","title":"Installation","text":""},{"location":"research-drive/connecting-to-research-drive/Via-Rclone/#manual-download-and-install","title":"Manual Download and Install","text":"<ul> <li>Download and install Rclone from Rclone's website</li> <li>Verify installation by running <code>rclone --version</code> in your terminal</li> </ul> <p>When using Windows, you can use the rclone command only from the folder where rclone.exe is located. The executable can be moved if needed.</p>"},{"location":"research-drive/connecting-to-research-drive/Via-Rclone/#script-download-and-install","title":"Script Download and Install","text":"<p>To install rclone on Linux/macOS/BSD systems, run:</p> <pre><code>sudo -v ; curl https://rclone.org/install.sh | sudo bash\n</code></pre>"},{"location":"research-drive/connecting-to-research-drive/Via-Rclone/#generate-app-credentials","title":"Generate App Credentials","text":"<ul> <li>Go to Research Drive Settings &gt; Security</li> <li>Click \"Create new app password\"</li> <li>Copy the password immediately - it is only displayed once and cannot be retrieved later</li> </ul>"},{"location":"research-drive/connecting-to-research-drive/Via-Rclone/#obscure-password","title":"Obscure Password","text":"<ul> <li>Open your terminal</li> <li>Run the command:     <pre><code>rclone obscure YOUR_APP_PASSWORD\n</code></pre></li> <li>Copy the outputted obscured password string</li> </ul>"},{"location":"research-drive/connecting-to-research-drive/Via-Rclone/#get-webdav-url","title":"Get WebDAV URL","text":"<ul> <li>Go to Research Drive &gt; Files &gt; Settings (in bottom left corner) &gt; WebDAV</li> <li>Copy the WebDAV URL</li> </ul> <p>The URL should follow this format: <pre><code>https://&lt;your-environment&gt;.surf.nl/remote.php/dav/files/&lt;your-username&gt;/\n</code></pre></p>"},{"location":"research-drive/connecting-to-research-drive/Via-Rclone/#configuration-setup","title":"Configuration Setup","text":"<p>Create or edit the rclone configuration file: - Linux/MacOS: <code>~/.config/rclone/rclone.conf</code> - Windows: <code>%USERPROFILE%\\.config\\rclone\\rclone.conf</code></p> <p>Add the following configuration: <pre><code>[cropxr]\ntype = webdav\nurl = https://cropxr.data.surf.nl/remote.php/dav/files/&lt;your-username&gt;\nvendor = nextcloud\nuser = &lt;your-username&gt;\npass = &lt;your-obscured-password&gt;\n</code></pre></p> <p>Replace: - <code>&lt;your-username&gt;</code> with your email address that you use to login to Research Drive - <code>&lt;your-obscured-password&gt;</code> with the obscured password from the previous step</p>"},{"location":"research-drive/connecting-to-research-drive/Via-Rclone/#mounting-commands","title":"Mounting Commands","text":"<p>Linux/MacOS: <pre><code>rclone mount \"cropxr:research_drive/folder\" /local/folder/ --vfs-cache-mode writes --use-cookies -v\n</code></pre></p> <p>Windows:</p> <p>For mounting in Windows, you need to install WinFsp. This means that you need administative priviledge to install programs on your computer, or you need to ask the systems admins for this program in advance. In the terminal from the folder that contains rclone:</p> <pre><code>rclone mount \"cropxr:research_drive/folder\" K: --vfs-cache-mode writes --use-cookies -v\n</code></pre> <p>The <code>--vfs-cache-mode writes</code> flag is an important Rclone configuration option that controls how file data is cached when using Rclone to mount a remote file system. When set to \"writes\", this option means:</p> <ul> <li>Files opened for reading are not cached initially</li> <li>Files opened for writing are cached during the entire upload</li> <li>File data read from the remote while a file is open is cached</li> </ul> <p>The <code>--use-cookies</code> flag in Rclone enables the use of cookies for authentication and session management when connecting to remote servers, particularly WebDAV servers like Research Drive (which is based on Nextcloud).</p> <p>Replace the paths in the example command with the actual path needed. The path of the folder on the research drive, should be either the complete path, or the path that is visible to/shared with the user. This likely looks like this for the full path <code>cropxr:cropxr (Projectfolder)/investigations/investigation_folder/study_folder</code> or like this for shared folders <code>cropxr:study_folder</code></p> <p>Best practice is to mount a specific folder (e.g., <code>WPC1</code>) rather than the root of Research Drive. This helps in managing permissions and access control more effectively.</p>"},{"location":"research-drive/connecting-to-research-drive/Via-Rclone/#copy-commands","title":"Copy Commands","text":"<p><pre><code>rclone copy /my/source/location \"cropxr:research_drive/destination/folder\"\n</code></pre> Replace the paths in the example command with the actual path needed. The path of the folder on the research drive, should be either the complete path, or the path that is visible to/shared with the user. This likely looks like this for the full path <code>cropxr:cropxr (Projectfolder)/investigations/investigation_folder/study_folder</code> or like this for shared folders <code>cropxr:study_folder</code></p> <p>This copies the file from the source to the research drive. When the source location is a folder, all the contents of the folder are copied to the desination. For large files it is recommended to add a time-out. The timeout should be 10 min per GB of the largest file that will be copied.</p> <pre><code>rclone copy --timeout 50m /my/source/location \"cropxr:research_drive/destination/folder\"\n</code></pre>"},{"location":"research-drive/connecting-to-research-drive/Via-a-Browser/","title":"Via a Browser","text":"<p>The CropXR project utilizes SURF Research Drive as our Phase II platform for secure data sharing and collaboration. Our Research Drive is hosted at https://cropxr.data.surfsara.nl/.</p>"},{"location":"research-drive/connecting-to-research-drive/Via-a-Browser/#getting-access","title":"Getting Access","text":"<p>Access to the CropXR Research Drive follows these steps:</p> <ol> <li> <p>Request Access: Follow this link</p> </li> <li> <p>Institutional Users: If you're affiliated with a Dutch research institution, you can log in using your institutional Single Sign-On (SSO) credentials.</p> </li> <li> <p>External Collaborators: Researchers without institutional SSO can access the platform through EduID. If you don't have an EduID account yet, you can create one at eduid.nl. Use the browser to create your EduID account. The mobile version sometimes has issues.</p> </li> <li> <p>Account Activation: After your request is approved, you'll receive an email invitation to the Research Drive. Follow the link in the invitation to set up your account.</p> </li> <li> <p>First Login: Upon your first successful login, system administrators will configure appropriate access permissions for you based on your project role. This may take up to 24 hours.</p> </li> </ol>"},{"location":"research-drive/connecting-to-research-drive/Via-a-Browser/#support","title":"Support","text":"<p>If you encounter any issues with the Research Drive access or have questions about data sharing protocols, please reach out to the platform administrators via the #research-drive Slack channel.</p>"}]}